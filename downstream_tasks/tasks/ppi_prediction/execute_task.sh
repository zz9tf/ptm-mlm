#!/bin/bash
# PPI Prediction Pipeline
# è›‹ç™½è´¨-è›‹ç™½è´¨ç›¸äº’ä½œç”¨é¢„æµ‹å®Œæ•´æµç¨‹è„šæœ¬

# æ£€æŸ¥å‚æ•°
if [ $# -ne 4 ]; then
    echo "Usage: $0 <adaptor_checkpoint> <model_name> <layer> <gpu_device>"
    echo "Example: $0 LoRA_combine EvolutionaryScale_esmc-600m-2024-12 30 4"
    echo "Example (no checkpoint): $0 None EvolutionaryScale_esmc-600m-2024-12 30 4"
    echo "Example (no checkpoint): $0 \"\" EvolutionaryScale_esmc-600m-2024-12 30 4"
    exit 1
fi

ADAPTOR_CHECKPOINT="$1"
# å¤„ç†ç©ºå­—ç¬¦ä¸²æˆ– "None" å­—ç¬¦ä¸²ï¼Œè½¬æ¢ä¸ºçœŸæ­£çš„ None
if [ -z "$ADAPTOR_CHECKPOINT" ] || [ "$ADAPTOR_CHECKPOINT" = "None" ] || [ "$ADAPTOR_CHECKPOINT" = "none" ]; then
    ADAPTOR_CHECKPOINT="None"
fi
MODEL_NAME="$2"
LAYER_INDEX="$3"
GPU_DEVICE="$4"

# æ¿€æ´»ç¯å¢ƒ
source /home/zz/miniconda3/etc/profile.d/conda.sh
conda activate ptm

set -e  # Exit on error
export CUDA_VISIBLE_DEVICES="${GPU_DEVICE}"

# ============================================
# é…ç½®å‚æ•° (Configuration)
# ============================================
WORK_DIR="/home/zz/zheng/ptm-mlm/downstream_tasks/tasks/ppi_prediction"
BASE_OUTPUT_DIR="/home/zz/zheng/ptm-mlm/downstream_tasks/outputs"

# åˆ›å»ºå¸¦æ—¥æœŸçš„è¾“å‡ºç›®å½•
DATE_STR=$(date +"%Y-%m-%d")
OUTPUT_DIR="${BASE_OUTPUT_DIR}/ppi_prediction_${ADAPTOR_CHECKPOINT}_${DATE_STR}"

# è®­ç»ƒå‚æ•°
BATCH_SIZE=512
NUM_EPOCHS=50
LEARNING_RATE=1e-4
DEVICE="cuda"
DROPOUT=0.3
MAX_LENGTH=2000

echo "ğŸ”„ Starting PPI prediction pipeline..."
if [ -z "$ADAPTOR_CHECKPOINT" ] || [ "$ADAPTOR_CHECKPOINT" = "None" ] || [ "$ADAPTOR_CHECKPOINT" = "none" ]; then
    echo "   Adaptor checkpoint: None (using raw embeddings)"
else
    echo "   Adaptor checkpoint: ${ADAPTOR_CHECKPOINT}"
fi
echo "   Model name: ${MODEL_NAME}"
echo "   Layer index: ${LAYER_INDEX}"
echo "   GPU device: ${GPU_DEVICE}"
echo "   Output dir: ${OUTPUT_DIR}"

# åˆ›å»ºè¾“å‡ºç›®å½•
mkdir -p "${OUTPUT_DIR}"

cd "${WORK_DIR}"

# ğŸ”§ æ„å»º Python å‘½ä»¤å‚æ•°
PYTHON_ARGS=(
    --output_dir "${OUTPUT_DIR}"
    --num_epochs ${NUM_EPOCHS}
    --batch_size ${BATCH_SIZE}
    --learning_rate ${LEARNING_RATE}
    --dropout ${DROPOUT}
    --max_length ${MAX_LENGTH}
    --device "${DEVICE}"
)

# ğŸ”§ model_name å¿…é¡»ä¼ é€’ï¼ˆä¸èƒ½ä¸ºç©ºï¼‰
if [ -z "$MODEL_NAME" ]; then
    echo "âŒ é”™è¯¯: model_name ä¸èƒ½ä¸ºç©º!"
    exit 1
fi
PYTHON_ARGS+=(--model_name "${MODEL_NAME}")

# ğŸ”§ åªæœ‰å½“ layer_index ä¸ä¸ºç©ºä¸”ä¸æ˜¯ "None" æ—¶æ‰æ·»åŠ ï¼ˆå› ä¸º Python æœŸæœ› int ç±»å‹ï¼‰
if [ -n "$LAYER_INDEX" ] && [ "$LAYER_INDEX" != "None" ] && [ "$LAYER_INDEX" != "none" ]; then
    PYTHON_ARGS+=(--layer_index ${LAYER_INDEX})
fi

# ğŸ”§ åªæœ‰å½“ adaptor_checkpoint ä¸ä¸ºç©ºä¸”ä¸æ˜¯ "None" æ—¶æ‰æ·»åŠ 
if [ -n "$ADAPTOR_CHECKPOINT" ] && [ "$ADAPTOR_CHECKPOINT" != "None" ] && [ "$ADAPTOR_CHECKPOINT" != "none" ]; then
    PYTHON_ARGS+=(--adaptor_checkpoint "${ADAPTOR_CHECKPOINT}")
fi

python3 train_and_evaluation.py "${PYTHON_ARGS[@]}"

echo "âœ… Step 2 å®Œæˆ: TransformerClassifierè®­ç»ƒå®Œæˆï¼Œæµ‹è¯•é›†è¯„ä¼°å®Œæˆ"
echo ""

# ============================================
# ğŸ‰ å®Œæ•´æµç¨‹æ‰§è¡Œå®Œæ¯•!
# ============================================
echo "============================================"
echo "ğŸ‰ å®Œæ•´æµç¨‹æ‰§è¡Œå®Œæ¯•!"
echo "============================================"
echo "è¾“å‡ºæ–‡ä»¶:"
echo "  - è®­ç»ƒå¥½çš„æ¨¡å‹: ${OUTPUT_DIR}/best_model.pt"
echo "  - è®­ç»ƒå†å²: ${OUTPUT_DIR}/training_history.json"
echo "  - è®­ç»ƒæ›²çº¿: ${OUTPUT_DIR}/training_curves.png"
echo "  - æµ‹è¯•æŒ‡æ ‡: ${OUTPUT_DIR}/test_metrics.json"
echo "  - è¾“å‡ºç›®å½•: ${OUTPUT_DIR}/"
echo "============================================"

