#!/bin/bash
# Phosphorylation Site Prediction Pipeline
# ç£·é…¸åŒ–ä½ç‚¹é¢„æµ‹å®Œæ•´æµç¨‹è„šæœ¬

source /home/zz/miniconda3/etc/profile.d/conda.sh
conda activate ptm-mamba
cd /home/zz/zheng/ptm-mlm/main_pipeline

set -e  # Exit on error
export CUDA_VISIBLE_DEVICES="0,1,2,4,5"

# ============================================
# é…ç½®å‚æ•° (Configuration)
# ============================================
WORK_DIR="/home/zz/zheng/ptm-mlm/downstream_tasks/p_site_prediction"
CHECKPOINT="${WORK_DIR}/best.ckpt"  # é¢„è®­ç»ƒæ¨¡å‹checkpointè·¯å¾„
TRAIN_DATA="${WORK_DIR}/PhosphositePTM.train.txt"
TEST_DATA="${WORK_DIR}/PhosphositePTM.test.txt"
VALID_DATA="${WORK_DIR}/PhosphositePTM.valid.txt"  # å¯é€‰
EMBEDDINGS_DIR="${WORK_DIR}/embeddings"
BATCH_SIZE=32
NUM_EPOCHS=10
LEARNING_RATE=1e-4
DEVICE="cuda"  # æˆ– "cpu"
LAMBDA_WEIGHT=0.5  # Weight (Î») for AUCMLoss in combined loss: loss = bce_loss + Î» * auc_loss
MAX_SEQUENCE_LENGTH=512  # æ»‘åŠ¨çª—å£å¤§å°ï¼ˆé»˜è®¤512ï¼Œä¸è®­ç»ƒé…ç½®ä¸€è‡´ï¼‰
WINDOW_OVERLAP=0.3  # æ»‘åŠ¨çª—å£é‡å æ¯”ä¾‹ï¼ˆ0.5è¡¨ç¤º50%é‡å ï¼‰
USE_SLIDING_WINDOW=true  # ä½¿ç”¨æ»‘åŠ¨çª—å£å¤„ç†é•¿åºåˆ—ï¼ˆæ¨èï¼Œç¡®ä¿æ‰€æœ‰ä½ç½®éƒ½è¢«å¤„ç†ï¼‰
MODEL_TYPE="esm2"  # æ¨¡å‹ç±»å‹: "mamba" æˆ– "esm2"
ESM2_MODEL_NAME="facebook/esm2_t33_650M_UR50D"  # ESM2æ¨¡å‹åç§°ï¼ˆä»…åœ¨MODEL_TYPE="esm2"æ—¶ä½¿ç”¨ï¼‰

cd "${WORK_DIR}"

# ============================================
# Step 1: ç”ŸæˆEmbeddings (Generate Embeddings)
# ============================================
echo "============================================"
echo "Step 1: ç”ŸæˆEmbeddings"
echo "============================================"

accelerate launch --num_processes=1 generate_embeddings.py \
    --model_type "${MODEL_TYPE}" \
    --checkpoint "${CHECKPOINT}" \
    --esm2_model_name "${ESM2_MODEL_NAME}" \
    --train_data "${TRAIN_DATA}" \
    --test_data "${TEST_DATA}" \
    --valid_data "${VALID_DATA}" \
    --output_dir "${EMBEDDINGS_DIR}" \
    --batch_size ${BATCH_SIZE} \
    --max_sequence_length ${MAX_SEQUENCE_LENGTH} \
    --window_overlap ${WINDOW_OVERLAP} \
    $([ "${USE_SLIDING_WINDOW}" = "true" ] && echo "--use_sliding_window" || echo "--no_sliding_window")

echo "âœ… Step 1 å®Œæˆ: Embeddingså·²ç”Ÿæˆ"
echo ""

# ============================================
# Step 2: è®­ç»ƒåˆ†ç±»å¤´å¹¶è¯„ä¼° (Train Classification Head and Evaluate)
# ============================================
echo "============================================"
echo "Step 2: è®­ç»ƒåˆ†ç±»å¤´å¹¶è¯„ä¼°"
echo "============================================"

python train_and_evaluation.py \
    --embeddings_dir "${EMBEDDINGS_DIR}" \
    --num_epochs ${NUM_EPOCHS} \
    --batch_size ${BATCH_SIZE} \
    --learning_rate ${LEARNING_RATE} \
    --output_dir "${WORK_DIR}" \
    --device "${DEVICE}" \
    --lambda_weight ${LAMBDA_WEIGHT}

echo "âœ… Step 2 å®Œæˆ: åˆ†ç±»å¤´è®­ç»ƒå®Œæˆï¼Œæµ‹è¯•é›†è¯„ä¼°å®Œæˆ"
echo ""

# echo "============================================"
# echo "ğŸ‰ å®Œæ•´æµç¨‹æ‰§è¡Œå®Œæ¯•!"
# echo "============================================"
# echo "è¾“å‡ºæ–‡ä»¶:"
# echo "  - Embeddings: ${EMBEDDINGS_DIR}/"
# echo "  - è®­ç»ƒå¥½çš„æ¨¡å‹: ${WORK_DIR}/trained_head.pt (åŒ…å«è®­ç»ƒ/éªŒè¯/æµ‹è¯•é›†æŒ‡æ ‡)"
# echo "============================================"

